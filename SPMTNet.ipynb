{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3vglFz7XgiLe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-01 21:11:44.459484: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-01 21:11:44.469149: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735787504.478071  178414 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735787504.480713  178414 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-01 21:11:44.490628: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, Dense, Dropout, Flatten, Bidirectional,TimeDistributed\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DFN and SPMT data with 3.2 V cutoff voltage\n",
    "# 0.2C\n",
    "DFN_02C = np.array(pd.read_csv('Dataset/SPMTNet/DFN_02C.csv',header = None))\n",
    "SPM_02C = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_02C.csv',header = None))[:17794]\n",
    "# 0.5C\n",
    "DFN_05C = np.array(pd.read_csv('Dataset/SPMTNet/DFN_05C.csv',header = None))[:7011]\n",
    "SPM_05C = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_05C.csv',header = None))\n",
    "# 1C\n",
    "DFN_1C = np.array(pd.read_csv('Dataset/SPMTNet/DFN_1C.csv',header = None))[:3426]\n",
    "SPM_1C = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_1C.csv',header = None))\n",
    "# 2C\n",
    "DFN_2C = np.array(pd.read_csv('Dataset/SPMTNet/DFN_2C.csv',header = None))[:1648]\n",
    "SPM_2C = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_2C.csv',header = None))\n",
    "# 3C\n",
    "DFN_3C = np.array(pd.read_csv('Dataset/SPMTNet/DFN_3C.csv',header = None))[:1067]\n",
    "SPM_3C = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_3C.csv',header = None))\n",
    "# 4C\n",
    "DFN_4C = np.array(pd.read_csv('Dataset/SPMTNet/DFN_4C.csv',header = None))[:784]\n",
    "SPM_4C = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_4C.csv',header = None))\n",
    "# 5C\n",
    "DFN_5C = np.array(pd.read_csv('Dataset/SPMTNet/DFN_5C.csv',header = None))[:618]\n",
    "SPM_5C = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_5C.csv',header = None))\n",
    "# 6C\n",
    "DFN_6C = np.array(pd.read_csv('Dataset/SPMTNet/DFN_6C.csv',header = None))[:509]\n",
    "SPM_6C = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_6C.csv',header = None))\n",
    "# 7C\n",
    "DFN_7C = np.array(pd.read_csv('Dataset/SPMTNet/DFN_7C.csv',header = None))[:429]\n",
    "SPM_7C = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_7C.csv',header = None))\n",
    "# 8C\n",
    "DFN_8C = np.array(pd.read_csv('Dataset/SPMTNet/DFN_8C.csv',header = None))[:368]\n",
    "SPM_8C = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_8C.csv',header = None))\n",
    "# 9C\n",
    "DFN_9C = np.array(pd.read_csv('Dataset/SPMTNet/DFN_9C.csv',header = None))[:321]\n",
    "SPM_9C = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_9C.csv',header = None))\n",
    "# 10C\n",
    "DFN_10C = np.array(pd.read_csv('Dataset/SPMTNet/DFN_10C.csv',header = None))[:284]\n",
    "SPM_10C = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_10C.csv',header = None))\n",
    "# UDDS\n",
    "DFN_UDDS = np.array(pd.read_csv('Dataset/SPMTNet/DFN_UDDSx2.csv',header = None))\n",
    "SPM_UDDS = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_UDDSx2.csv',header = None))[1:]\n",
    "# US06\n",
    "DFN_US06 = np.array(pd.read_csv('Dataset/SPMTNet/DFN_US06x6.csv',header = None))\n",
    "SPM_US06 = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_US06x6.csv',header = None))[1:]\n",
    "# LA92\n",
    "DFN_LA92 = np.array(pd.read_csv('Dataset/SPMTNet/DFN_LA92x2.csv',header = None))\n",
    "SPM_LA92 = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_LA92x2.csv',header = None))[1:]\n",
    "# SC04\n",
    "DFN_SC04 = np.array(pd.read_csv('Dataset/SPMTNet/DFN_SC04x4.csv',header = None))\n",
    "SPM_SC04 = np.array(pd.read_csv('Dataset/SPMTNet/SPMT_SC04x4.csv',header = None))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "q6yFkOYpOQNT",
    "outputId": "2dac1540-aeec-4a6b-f5b8-a4c58f5a26f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenate SPM train length: 38350\n",
      "Concatenate DFN train length: 38350\n"
     ]
    }
   ],
   "source": [
    "# Concatenate 0.2/0.5/1/2/4/6/7/10C and US06/SC04 discharging data for training\n",
    "# and keep other datasets for testing\n",
    "DFN = np.concatenate((DFN_02C,DFN_05C),axis=0)\n",
    "DFN = np.concatenate((DFN,DFN_1C),axis=0)\n",
    "DFN = np.concatenate((DFN,DFN_2C),axis=0)\n",
    "# DFN = np.concatenate((DFN,DFN_3C),axis=0)\n",
    "DFN = np.concatenate((DFN,DFN_4C),axis=0)\n",
    "# DFN = np.concatenate((DFN,DFN_5C),axis=0)\n",
    "DFN = np.concatenate((DFN,DFN_6C),axis=0)\n",
    "# DFN = np.concatenate((DFN,DFN_7C),axis=0)\n",
    "DFN = np.concatenate((DFN,DFN_8C),axis=0)\n",
    "# DFN = np.concatenate((DFN,DFN_9C),axis=0)\n",
    "DFN = np.concatenate((DFN,DFN_10C),axis=0)\n",
    "# DFN = np.concatenate((DFN,DFN_UDDS),axis=0)\n",
    "DFN = np.concatenate((DFN,DFN_US06),axis=0)\n",
    "DFN = np.concatenate((DFN,DFN_LA92),axis=0)\n",
    "# DFN = np.concatenate((DFN,DFN_SC04),axis=0)\n",
    "\n",
    "SPM = np.concatenate((SPM_02C,SPM_05C),axis=0)\n",
    "SPM = np.concatenate((SPM,SPM_1C),axis=0)\n",
    "SPM = np.concatenate((SPM,SPM_2C),axis=0)\n",
    "# SPM = np.concatenate((SPM,SPM_3C),axis=0)\n",
    "SPM = np.concatenate((SPM,SPM_4C),axis=0)\n",
    "# SPM = np.concatenate((SPM,SPM_5C),axis=0)\n",
    "SPM = np.concatenate((SPM,SPM_6C),axis=0)\n",
    "# SPM = np.concatenate((SPM,SPM_7C),axis=0)\n",
    "SPM = np.concatenate((SPM,SPM_8C),axis=0)\n",
    "# SPM = np.concatenate((SPM,SPM_9C),axis=0)\n",
    "SPM = np.concatenate((SPM,SPM_10C),axis=0)\n",
    "# SPM = np.concatenate((SPM,SPM_UDDS),axis=0)\n",
    "SPM = np.concatenate((SPM,SPM_US06),axis=0)\n",
    "SPM = np.concatenate((SPM,SPM_LA92),axis=0)\n",
    "# SPM = np.concatenate((SPM,SPM_SC04),axis=0)\n",
    "\n",
    "print(\"Concatenate SPM train length: \" + str(len(SPM)))\n",
    "print(\"Concatenate DFN train length: \" + str(len(DFN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Rg58-stmsIw"
   },
   "outputs": [],
   "source": [
    "#Construct training data\n",
    "trainX = np.zeros((len(SPM),4))\n",
    "# trainX[:,0] = SPM[:,0] # 0: Voltage\n",
    "trainX[:,0] = SPM[:,1] # 1: Bulk SoC\n",
    "trainX[:,1] = SPM[:,2] # 2: Surface SoC\n",
    "trainX[:,2] = SPM[:,3] # 3: Temperature\n",
    "trainX[:,3] = SPM[:,4] # 4: Current  \n",
    "\n",
    "# trainY = DFN.reshape(len(DFN),1) - SPM[:,0].reshape(len(SPM),1) # SPMTNet-1: learning voltage residual\n",
    "trainY = DFN # SPMTNet-2: learning voltage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7KUXDHWGODob"
   },
   "outputs": [],
   "source": [
    "# normalize input and output data for training\n",
    "scaler1 = MinMaxScaler()\n",
    "scaler1.fit(trainX)\n",
    "normalizedX = scaler1.transform(trainX)\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler2.fit(trainY)\n",
    "normalizedY = scaler2.transform(trainY)\n",
    "trainX = normalizedX\n",
    "trainY = normalizedY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fexFYjXtNSFr",
    "outputId": "1aadb99c-5ea1-45f2-a117-4e555129ed55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Score: RMSE 0.032395216472898364\n"
     ]
    }
   ],
   "source": [
    "initScore = math.sqrt(mean_squared_error(DFN.reshape(len(DFN),1), SPM[:,0].reshape(len(SPM),1)))\n",
    "print(\"Initial Score: RMSE \" + str(initScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "RYPbk5_xilcU",
    "outputId": "f0f73a72-46ce-4c21-86c3-d81af3a04675"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/tuhao/python3_12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1735787518.237630  178414 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9536 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,249</span> (4.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,249\u001b[0m (4.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,249</span> (4.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,249\u001b[0m (4.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(SimpleRNN(units=32,input_shape=(look_back + 1,5)))\n",
    "# # model.add(LSTM(units=32,input_shape=(look_back + 1,4)))\n",
    "# model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.add(Dense(32, input_dim=4, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YrtSJmeii6y4",
    "outputId": "2c4f3e0a-b3e5-40ac-f9be-9666599fff66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735787519.455932  178607 service.cc:148] XLA service 0x7f9a34005640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735787519.455954  178607 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Ti, Compute Capability 8.6\n",
      "2025-01-01 21:11:59.466952: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1735787519.511273  178607 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 216/1199\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.0268"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1735787520.413441  178607 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.0085 \n",
      "Epoch 2/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - loss: 2.9223e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - loss: 1.8709e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - loss: 1.4521e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - loss: 1.2057e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - loss: 1.0228e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 9.4209e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 8.4681e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 8.2632e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.0212e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - loss: 7.2904e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6.9453e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - loss: 6.4987e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 6.2954e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.2171e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.0611e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.0932e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - loss: 5.7573e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - loss: 5.6076e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.5243e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.4412e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.0150e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - loss: 5.0489e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4.9590e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - loss: 5.0607e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.2868e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.8389e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - loss: 4.8018e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4.8868e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - loss: 4.5919e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4.9356e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4.8010e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4.6681e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - loss: 4.2109e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4.5864e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - loss: 4.3577e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - loss: 4.6692e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - loss: 4.3530e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - loss: 4.1704e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - loss: 4.0808e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step - loss: 4.7393e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4.2493e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - loss: 4.3001e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4.0526e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step - loss: 4.0313e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4.1528e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4.4770e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4.0562e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4.1231e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.9971e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.9855e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4.1204e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4.1056e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4.0380e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.9458e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4.0297e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.7713e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.8729e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.9009e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4.0895e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.5575e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.8560e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.9207e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.6745e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.8813e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.6600e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.7145e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.9061e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.5858e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.9768e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.6496e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.8727e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.7199e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.4302e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.5079e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.6585e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.4467e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.6222e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.4279e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.4487e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.1739e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.2773e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.2311e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.3713e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.1159e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.4881e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.1769e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.2036e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.1647e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.1272e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.0202e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.0570e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.1362e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.0315e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.5306e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.0795e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.2316e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.0652e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.0171e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.9837e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.0805e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.9304e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.1012e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.6543e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.9391e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.7772e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.7026e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.7255e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.7422e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.7731e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.7869e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.8350e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.7603e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.7933e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.6688e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.7940e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.7599e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3861e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.6669e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.5598e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.5871e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.5723e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.5999e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.4669e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.4567e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.6558e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.6173e-05\n",
      "Epoch 128/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.4199e-05\n",
      "Epoch 129/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3457e-05\n",
      "Epoch 130/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.7229e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.4825e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.6850e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.5207e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3869e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.5046e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.4454e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.4978e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.4841e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.4758e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.5890e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.3842e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.3976e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.2645e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.3204e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.2818e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.5363e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3163e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3509e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3758e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.4450e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3631e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3907e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3441e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3529e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3711e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.2623e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.4638e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.2257e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.6342e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.4123e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.2325e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3226e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3795e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3380e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.4296e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.3791e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.1074e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.2523e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3462e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.4076e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.2667e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.5126e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3349e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.2796e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.2430e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.2982e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3207e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.2729e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.2395e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.2721e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3302e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.2096e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3414e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.1958e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.2023e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.2384e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.1174e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.1588e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.3292e-05\n",
      "Epoch 190/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.0318e-05\n",
      "Epoch 191/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.2116e-05\n",
      "Epoch 192/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.1018e-05\n",
      "Epoch 193/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3412e-05\n",
      "Epoch 194/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.3100e-05\n",
      "Epoch 195/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.0788e-05\n",
      "Epoch 196/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.1563e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.2326e-05\n",
      "Epoch 198/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.1833e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.2149e-05\n",
      "Epoch 200/200\n",
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.1037e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f9b84515f40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train NN\n",
    "model.fit(trainX, trainY, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "V1YV64uHKavY",
    "outputId": "20a55112-a2a9-4b55-9145-a288133e224d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Train Score: RMSE 0.005288601710673378\n"
     ]
    }
   ],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "trainPredict = scaler2.inverse_transform(trainPredict.reshape(len(trainPredict),1))\n",
    "trainScore = math.sqrt(mean_squared_error(DFN, trainPredict.reshape(len(trainPredict),1)))\n",
    "print(\"Train Score: RMSE \" + str(trainScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data separately\n",
    "SPM_T = SPM_UDDS\n",
    "DFN_T = DFN_UDDS\n",
    "\n",
    "#Construct testing data\n",
    "testX = np.zeros((len(SPM_T),4))\n",
    "testX[:,0] = SPM_T[:,1]\n",
    "testX[:,1] = SPM_T[:,2]\n",
    "testX[:,2] = SPM_T[:,3]\n",
    "testX[:,3] = SPM_T[:,4]\n",
    "# testX[:,4] = SPM_T[:,5]\n",
    "\n",
    "# # SPMTNet-1: learning voltage residual\n",
    "# testY =  DFN_T.reshape(len(DFN_T),1) - SPM_T[:,0].reshape(len(SPM_T),1) \n",
    "# SPMTNet-2: learning voltage\n",
    "testY = DFN_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ToHUhxocURJ0",
    "outputId": "d440354f-145d-4786-9392-aa5d610020f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "Test Score: RMSE 0.010212729545114731\n",
      "Initial Score: RMSE 0.02768061551249933\n"
     ]
    }
   ],
   "source": [
    "# Prediction of the testing case\n",
    "normalizedXtest = scaler1.transform(testX)\n",
    "testPredict = model.predict(normalizedXtest)\n",
    "testPredict = scaler2.inverse_transform(testPredict)\n",
    "testScore = math.sqrt(mean_squared_error(testY,testPredict.reshape(len(testPredict),1)))\n",
    "print(\"Test Score: RMSE \" + str(testScore))\n",
    "InitialScore = math.sqrt(mean_squared_error(DFN_T, SPM_T[:,0]))\n",
    "print(\"Initial Score: RMSE \" + str(InitialScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for the hybrid model\n",
    "np.savetxt('Journal_results/HYBRID2/predict_Test_UDDS.csv', testPredict.reshape(len(testPredict),1), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hybrid Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
